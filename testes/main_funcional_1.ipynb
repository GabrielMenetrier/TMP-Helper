{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411ab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baixar_dados(tickers, start_date='2020-01-01', end_date='2025-01-01'):\n",
    "\n",
    "    data = yf.download(tickers, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "    prices = data['Close']\n",
    "\n",
    "    prices = prices.dropna(axis=1, how='any')\n",
    "\n",
    "    returns = prices.pct_change().dropna()\n",
    "\n",
    "    #Pra que eu vou usar isso?\n",
    "    retorno_acumulado = (1 + returns).cumprod()\n",
    "    final_retorno_acumulado = retorno_acumulado.iloc[-1] if not retorno_acumulado.empty else pd.Series(1, index=data.columns)\n",
    "\n",
    "\n",
    "    return data,returns,final_retorno_acumulado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5119bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_para_cluster(data,retorno,final_retorno_acumulado):\n",
    "\n",
    "    features = pd.DataFrame(index=data['Close'].columns)\n",
    "\n",
    "    features['Retorno_Medio'] = retorno.mean() * 252\n",
    "\n",
    "    features['Volatilidade'] = retorno.std() * np.sqrt(252)\n",
    "\n",
    "    features['Sharpe'] = np.where(\n",
    "        features['Volatilidade'] > 0,\n",
    "        features['Retorno_Medio'] / features['Volatilidade'],\n",
    "        0\n",
    "        )\n",
    "\n",
    "    features['Retorno_Acumulado'] = (final_retorno_acumulado - 1).fillna(0)\n",
    "\n",
    "    features['Skewness'] = retorno.skew().fillna(0)\n",
    "\n",
    "    features['Kurtosis'] = retorno.kurtosis().fillna(0)\n",
    "\n",
    "\n",
    "    cummax = data.cummax()\n",
    "    drawdown = (data - cummax) / cummax\n",
    "    features['Max_Drawdown'] = drawdown.min().fillna(0)\n",
    "\n",
    "\n",
    "    # Correlação média\n",
    "    corr_matrix = retorno.corr()\n",
    "    n = len(corr_matrix)\n",
    "    if n > 1:\n",
    "        corr_sum = corr_matrix.values.sum() - n  # Subtrair diagonal\n",
    "        features['Corr_Media'] = corr_sum / (n * (n - 1))\n",
    "    else:\n",
    "        features['Corr_Media'] = 0\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features_scaled = imputer.fit_transform(features)\n",
    "\n",
    "\n",
    "    features = features.replace([np.inf, -np.inf], np.nan)\n",
    "    features = features.fillna(0)\n",
    "\n",
    "    return features, features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ef777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_cotovelo(features_scaled):\n",
    "    n_samples = len(features_scaled)\n",
    "    min_k = 2\n",
    "    max_k = min(8, max(2, n_samples - 1))\n",
    "\n",
    "    if max_k < min_k:\n",
    "        optimal_k = 2\n",
    "        print(f\"⚠️ Poucos dados. Usando k={optimal_k}\")\n",
    "        inertias = []\n",
    "        silhouette_scores = []\n",
    "        K = [optimal_k]\n",
    "    else:\n",
    "        K = list(range(min_k, max_k + 1))\n",
    "        inertias = []\n",
    "        silhouette_scores = []\n",
    "        \n",
    "        for k in K:\n",
    "            try:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "                kmeans.fit(features_scaled)\n",
    "                inertias.append(kmeans.inertia_)\n",
    "                \n",
    "                if k < n_samples:\n",
    "                    score = silhouette_score(features_scaled, kmeans.labels_)\n",
    "                    silhouette_scores.append(score)\n",
    "            except:\n",
    "                inertias.append(float('inf'))\n",
    "                silhouette_scores.append(0)\n",
    "        \n",
    "        # Encontrar cotovelo\n",
    "        if len(inertias) >= 3:\n",
    "            # Método simples: escolher k onde a redução de inércia diminui\n",
    "            reductions = np.diff(inertias)\n",
    "            if len(reductions) > 0:\n",
    "                optimal_k = min_k + np.argmin(reductions) + 1\n",
    "            else:\n",
    "                optimal_k = 3\n",
    "        else:\n",
    "            optimal_k = min(3, max_k)\n",
    "        \n",
    "        optimal_k = max(min_k, min(optimal_k, max_k))\n",
    "        return optimal_k, inertias, silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28fa08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters(features_scaled, optimal_k):\n",
    "\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "    return kmeans, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2727f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_df(data, clusters, features, final_retorno):\n",
    "\n",
    "    df_clusters = pd.DataFrame({\n",
    "        'Ticker': data['Close'].columns,\n",
    "        'Cluster': clusters\n",
    "    })\n",
    "\n",
    "    df_combinado = pd.concat([\n",
    "        df_clusters.set_index('Ticker'),\n",
    "        features,\n",
    "        pd.Series(final - 1, name='Retorno_Total', index=data['Close'].columns)\n",
    "    ], axis=1)\n",
    "\n",
    "    return df_combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a10f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio(returns,data, df_combinado, optimal_k):\n",
    "\n",
    "    tickers_selecionados = []\n",
    "    for cluster_id in range(optimal_k):\n",
    "        cluster_data = df_combinado[df_combinado['Cluster'] == cluster_id]\n",
    "        if len(cluster_data) > 0:\n",
    "            # Selecionar o melhor de cada cluster\n",
    "            best_ticker = cluster_data['Retorno_Total'].idxmax()\n",
    "            tickers_selecionados.append(best_ticker)\n",
    "            print(f\"Cluster {cluster_id}: {best_ticker} (Retorno: {cluster_data.loc[best_ticker, 'Retorno_Total']*100:.2f}%)\")\n",
    "\n",
    "    if not tickers_selecionados:\n",
    "        tickers_selecionados = list(data.columns[:3])\n",
    "    \n",
    "    portfolio_all = returns.mean(axis=1)\n",
    "    retorno_acumulado_all = (1 + portfolio_all).cumprod()\n",
    "\n",
    "    # Carteira selecionada\n",
    "    if len(tickers_selecionados) > 0:\n",
    "        dados_selecionados = data[tickers_selecionados]\n",
    "        weights = [1/len(tickers_selecionados)] * len(tickers_selecionados)\n",
    "        portfolio_selected = dados_selecionados.pct_change().dropna().dot(weights)\n",
    "        retorno_acumulado_selected = (1 + portfolio_selected).cumprod()\n",
    "    else:\n",
    "        portfolio_selected = portfolio_all\n",
    "        retorno_acumulado_selected = retorno_acumulado_all\n",
    "    tickers_selecionados_sem_close = [x[1] for x in tickers_selecionados]\n",
    "    return tickers_selecionados_sem_close, retorno_acumulado_all, retorno_acumulado_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "708c51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_graficos(features, clusters, retorno,\n",
    "                retorno_acumulado_all, retorno_acumulado_selected, \n",
    "                df_combinado, silhouette_scores, K, inertias,\n",
    "                optimal_k, tickers_selecionados\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Gera 9 gráficos diferentes e os salva na pasta 'static'.\n",
    "    \"\"\"\n",
    "    os.makedirs('static', exist_ok=True)  # Garante que a pasta 'static' existe\n",
    "\n",
    "    # 1. Método do Cotovelo\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if len(K) > 1 and len(inertias) > 1:\n",
    "        plt.plot(K, inertias, 'bo-', linewidth=2)\n",
    "        plt.axvline(x=optimal_k, color='red', linestyle='--', label=f'K ótimo = {optimal_k}')\n",
    "        plt.xlabel('Número de Clusters')\n",
    "        plt.ylabel('Inércia')\n",
    "        plt.title('Método do Cotovelo')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f'K = {optimal_k}', ha='center', va='center', fontsize=14)\n",
    "        plt.title('Clusters')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_cotovelo.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. PCA Visualization\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if features.shape[0] > 1 and features.shape[1] > 1:\n",
    "        try:\n",
    "            pca = PCA(n_components=2)\n",
    "            features_pca = pca.fit_transform(features)\n",
    "            scatter = plt.scatter(features_pca[:, 0], features_pca[:, 1], \n",
    "                                   c=clusters, cmap='viridis', s=100, alpha=0.7)\n",
    "            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "            plt.title('Visualização PCA dos Clusters')\n",
    "            plt.colorbar(scatter)\n",
    "        except:\n",
    "            plt.text(0.5, 0.5, 'PCA não disponível', ha='center', va='center')\n",
    "            plt.title('PCA')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes', ha='center', va='center')\n",
    "        plt.title('PCA')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_pca.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Comparação de Carteiras\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if not retorno_acumulado_all.empty:\n",
    "        retorno_acumulado_all.plot(label='Todos os Tickers', linewidth=2)\n",
    "        retorno_acumulado_selected.plot(label='Seleção por Clusters', linewidth=2, color='red')\n",
    "        plt.title('Comparação de Desempenho')\n",
    "        plt.ylabel('Retorno Acumulado')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_comparacao_carteiras.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Distribuição de Retornos\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if not retorno.empty:\n",
    "        retorno.boxplot(rot=45)\n",
    "        plt.title('Distribuição de Retornos')\n",
    "        plt.ylabel('Retorno Diário')\n",
    "        plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_distribuicao_retornos.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 5. Matriz de Correlação\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if len(tickers_selecionados) > 1 and not retorno.empty:\n",
    "        corr_selected = retorno[tickers_selecionados].corr()\n",
    "        sns.heatmap(corr_selected, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                    vmin=-1, vmax=1, cbar_kws={'shrink': 0.8})\n",
    "        plt.title('Correlação - Carteira Selecionada')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'N/A', ha='center', va='center')\n",
    "        plt.title('Correlação')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_correlacao.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Risk-Return Map\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if not df_combinado.empty:\n",
    "        for cluster_id in range(optimal_k):\n",
    "            cluster_data = df_combinado[df_combinado['Cluster'] == cluster_id]\n",
    "            if len(cluster_data) > 0:\n",
    "                plt.scatter(cluster_data['Volatilidade']*100, \n",
    "                            cluster_data['Retorno_Medio']*100,\n",
    "                            label=f'Cluster {cluster_id}', s=100, alpha=0.7)\n",
    "        plt.xlabel('Volatilidade Anual (%)')\n",
    "        plt.ylabel('Retorno Anual (%)')\n",
    "        plt.title('Mapa Risco-Retorno')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_risco_retorno.png')\n",
    "    plt.close()\n",
    "    '''\n",
    "    # 7. Silhouette Scores\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if len(silhouette_scores) > 1:\n",
    "        plt.plot(K[:len(silhouette_scores)], silhouette_scores, 'go-', linewidth=2)\n",
    "        plt.axvline(x=optimal_k, color='red', linestyle='--')\n",
    "        plt.xlabel('Número de Clusters')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Score')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'N/A', ha='center', va='center')\n",
    "        plt.title('Silhouette Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_silhouette.png')\n",
    "    plt.close()\n",
    "    '''\n",
    "    # 8. Performance Metrics\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    try:\n",
    "        metrics = pd.DataFrame({\n",
    "            'Todos': [\n",
    "                (retorno_acumulado_all.iloc[-1] - 1) * 100,\n",
    "                retorno.std() * np.sqrt(252) * 100,\n",
    "                (retorno.mean() / retorno.std()) * np.sqrt(252) if retorno.std() > 0 else 0\n",
    "            ],\n",
    "            'Selecionados': [\n",
    "                (retorno_acumulado_selected.iloc[-1] - 1) * 100,\n",
    "                retorno.std() * np.sqrt(252) * 100,\n",
    "                (retorno.mean() / retorno.std()) * np.sqrt(252) if retorno.std() > 0 else 0\n",
    "            ]\n",
    "        }, index=['Retorno Total (%)', 'Volatilidade (%)', 'Sharpe Ratio'])\n",
    "        \n",
    "        metrics.plot(kind='bar', alpha=0.8)\n",
    "        plt.title('Métricas de Performance')\n",
    "        plt.ylabel('Valor')\n",
    "        plt.legend(title='Carteira')\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    except:\n",
    "        plt.text(0.5, 0.5, 'Métricas não disponíveis', ha='center', va='center')\n",
    "        plt.title('Métricas')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_metricas.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 9. Composição da Carteira\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if len(tickers_selecionados) > 0:\n",
    "        sizes = [100/len(tickers_selecionados)] * len(tickers_selecionados)\n",
    "        colors = plt.cm.Set3(range(len(tickers_selecionados)))\n",
    "        plt.pie(sizes, labels=tickers_selecionados, colors=colors, autopct='%1.1f%%')\n",
    "        plt.title('Composição da Carteira Otimizada')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Sem seleção', ha='center', va='center')\n",
    "        plt.title('Composição')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('static/grafico_composicao_carteira.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d15620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_otimizacao(tickers):\n",
    "    \n",
    "    data, returns, final = baixar_dados(tickers)\n",
    "\n",
    "    features, features_scaled = features_para_cluster(data, returns, final)\n",
    "    \n",
    "    optimal_k, inertias, silhouette_scores= cluster_cotovelo(features_scaled)\n",
    "    \n",
    "    k_means, cluster = clusters(features_scaled, optimal_k)\n",
    "\n",
    "    df_combinado = clusters_df(data,k_means,features,final)\n",
    "\n",
    "    tickers_selecionados, retorno_acumulado_all, retorno_acumulado_selected = portfolio(returns, data,df_combinado, optimal_k)\n",
    "    print(tickers_selecionados)\n",
    "    gerar_graficos(features, cluster, returns, retorno_acumulado_all,\n",
    "    retorno_acumulado_selected, df_combinado, silhouette_scores, list(range(2, 2 + len(inertias))), inertias,\n",
    "    optimal_k, tickers_selecionados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2122cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_7352\\4244472927.py:6: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date, progress=False)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['Retorno_Medio' 'Volatilidade' 'Retorno_Acumulado' 'Skewness' 'Kurtosis'\n",
      " 'Max_Drawdown']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_7352\\1180319641.py:22: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  portfolio_selected = dados_selecionados.pct_change().dropna().dot(weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOVA11.SA', 'DIA', 'EWZ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:646: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_7352\\2964853862.py:100: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    }
   ],
   "source": [
    "tickers = [\n",
    "    \"PETR4.SA\", \"VALE3.SA\", \"ITUB4.SA\", \"BBDC4.SA\", \"ABEV3.SA\",\n",
    "    \"BBAS3.SA\", \"ELET3.SA\", \"RENT3.SA\", \"WEGE3.SA\", \"SUZB3.SA\",\n",
    "    \"MGLU3.SA\", \"B3SA3.SA\", \"GGBR4.SA\", \"BRFS3.SA\", \"CSNA3.SA\",\n",
    "    \"PRIO3.SA\", \"LREN3.SA\", \"KLBN11.SA\", \"HAPV3.SA\", \"EQTL3.SA\"\n",
    "]\n",
    "\n",
    "acoes_eua = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\",\n",
    "    \"META\", \"TSLA\", \"BRK-B\", \"JPM\", \"JNJ\",\n",
    "    \"V\", \"PG\", \"XOM\", \"HD\", \"MA\",\n",
    "    \"UNH\", \"PFE\", \"DIS\", \"KO\", \"NFLX\"\n",
    "]\n",
    "\n",
    "etfs = [\n",
    "    \"SPY\", \"QQQ\", \"IWM\", \"DIA\", \"VTI\",\n",
    "    \"IVV\", \"VEA\", \"VWO\", \"EWZ\", \"BOVA11.SA\",\n",
    "    \"SMAL11.SA\", \"IVVB11.SA\", \"XLF\", \"XLE\", \"XLK\",\n",
    "    \"XLY\", \"XLI\", \"VNQ\", \"GDX\", \"GLD\"\n",
    "]\n",
    "\n",
    "main_otimizacao(etfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
